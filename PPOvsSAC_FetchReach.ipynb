{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMknsZ+80jEeb4sIolFIMTZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akkki28/PPOvsSAC/blob/main/PPOvsSAC_FetchReach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3m1GHL4Nm81",
        "outputId": "1f385a71-f5a5-45da-cbe7-7785416aa597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium_robotics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOuJVjzVNsib",
        "outputId": "af1ac7a3-7580-4097-a8b6-69e901858c54"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium_robotics\n",
            "  Downloading gymnasium_robotics-1.3.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting mujoco<3.2.0,>=2.2.0 (from gymnasium_robotics)\n",
            "  Downloading mujoco-3.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m461.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium_robotics) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium_robotics) (1.0.0)\n",
            "Collecting PettingZoo>=1.23.0 (from gymnasium_robotics)\n",
            "  Downloading pettingzoo-1.24.3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: Jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium_robotics) (3.1.5)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from gymnasium_robotics) (2.37.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->gymnasium_robotics) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->gymnasium_robotics) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->gymnasium_robotics) (0.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.0.3->gymnasium_robotics) (3.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mujoco<3.2.0,>=2.2.0->gymnasium_robotics) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.11/dist-packages (from mujoco<3.2.0,>=2.2.0->gymnasium_robotics) (1.12.0)\n",
            "Collecting glfw (from mujoco<3.2.0,>=2.2.0->gymnasium_robotics)\n",
            "  Downloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.11/dist-packages (from mujoco<3.2.0,>=2.2.0->gymnasium_robotics) (3.1.9)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio->gymnasium_robotics) (11.1.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium_robotics) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium_robotics) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium_robotics) (3.21.0)\n",
            "Downloading gymnasium_robotics-1.3.1-py3-none-any.whl (26.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mujoco-3.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pettingzoo-1.24.3-py3-none-any.whl (847 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.8/847.8 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: glfw, PettingZoo, mujoco, gymnasium_robotics\n",
            "Successfully installed PettingZoo-1.24.3 glfw-2.8.0 gymnasium_robotics-1.3.1 mujoco-3.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable_baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYSB8iJuNuJO",
        "outputId": "1d62804a-41fe-4b60-c44a-80ebe4bb72ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.0.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.5.1+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gymnasium as gym\n",
        "import gymnasium_robotics\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3 import PPO,SAC\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ],
      "metadata": {
        "id": "SBB3didhN7B9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"./logs_PPO/\"\n",
        "os.makedirs(log_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "1oQJuq0QNwCt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "import numpy as np\n",
        "\n",
        "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
        "    def __init__(self, check_freq: int, log_dir: str, verbose=1):\n",
        "        super().__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "        self.log_dir = log_dir\n",
        "        self.save_path = os.path.join(log_dir, \"best_model\")\n",
        "        self.best_mean_reward = -np.inf\n",
        "\n",
        "    def _init_callback(self) -> None:\n",
        "        if self.save_path is not None:\n",
        "            os.makedirs(self.save_path, exist_ok=True)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            x, y = ts2xy(load_results(self.log_dir), \"timesteps\")\n",
        "            if len(x) > 0:\n",
        "                mean_reward = np.mean(y[-100:])\n",
        "                if self.verbose > 0:\n",
        "                    print(f\"Num timesteps: {self.num_timesteps}\")\n",
        "                    print(\n",
        "                        f\"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}\"\n",
        "                    )\n",
        "\n",
        "                if mean_reward > self.best_mean_reward:\n",
        "                    self.best_mean_reward = mean_reward\n",
        "                    if self.verbose > 0:\n",
        "                        print(f\"Saving new best model to {self.save_path}.zip\")\n",
        "                    self.model.save(self.save_path)\n",
        "\n",
        "        return True"
      ],
      "metadata": {
        "id": "ZGHmggA0N18D"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir)\n",
        "\n",
        "gym.register_envs(gymnasium_robotics)\n",
        "env = gym.make('FetchReachDense-v3')\n",
        "env = Monitor(env, log_dir)\n",
        "vec_env = make_vec_env(lambda: env, n_envs=1)\n",
        "\n",
        "model1 = PPO(\"MultiInputPolicy\",vec_env, verbose=1)\n",
        "model1.learn(total_timesteps=25000,callback=callback)\n",
        "model1.save(\"ppo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAo70mWwOTWZ",
        "outputId": "637cdaae-211b-4a17-e423-7c6786bf53fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Num timesteps: 1000\n",
            "Best mean reward: -inf - Last mean reward per episode: -28.44\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 2000\n",
            "Best mean reward: -28.44 - Last mean reward per episode: -29.44\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -29.4    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    fps             | 373      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 5        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Num timesteps: 3000\n",
            "Best mean reward: -28.44 - Last mean reward per episode: -28.41\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 4000\n",
            "Best mean reward: -28.41 - Last mean reward per episode: -28.40\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -28.5       |\n",
            "|    success_rate         | 0           |\n",
            "| time/                   |             |\n",
            "|    fps                  | 360         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 11          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005182788 |\n",
            "|    clip_fraction        | 0.0535      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.67       |\n",
            "|    explained_variance   | -0.0157     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.75        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00416    |\n",
            "|    std                  | 0.997       |\n",
            "|    value_loss           | 15.1        |\n",
            "-----------------------------------------\n",
            "Num timesteps: 5000\n",
            "Best mean reward: -28.40 - Last mean reward per episode: -27.65\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 6000\n",
            "Best mean reward: -27.65 - Last mean reward per episode: -26.92\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -26.9       |\n",
            "|    success_rate         | 0           |\n",
            "| time/                   |             |\n",
            "|    fps                  | 344         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 17          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006896054 |\n",
            "|    clip_fraction        | 0.0678      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.65       |\n",
            "|    explained_variance   | 0.188       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.95        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00791    |\n",
            "|    std                  | 0.991       |\n",
            "|    value_loss           | 9.48        |\n",
            "-----------------------------------------\n",
            "Num timesteps: 7000\n",
            "Best mean reward: -26.92 - Last mean reward per episode: -25.94\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 8000\n",
            "Best mean reward: -25.94 - Last mean reward per episode: -24.87\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -24.7       |\n",
            "|    success_rate         | 0           |\n",
            "| time/                   |             |\n",
            "|    fps                  | 350         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 23          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011207456 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.64       |\n",
            "|    explained_variance   | 0.58        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.3         |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0151     |\n",
            "|    std                  | 0.99        |\n",
            "|    value_loss           | 4.88        |\n",
            "-----------------------------------------\n",
            "Num timesteps: 9000\n",
            "Best mean reward: -24.87 - Last mean reward per episode: -23.50\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 10000\n",
            "Best mean reward: -23.50 - Last mean reward per episode: -22.78\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -22.7       |\n",
            "|    success_rate         | 0           |\n",
            "| time/                   |             |\n",
            "|    fps                  | 350         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 29          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018508269 |\n",
            "|    clip_fraction        | 0.215       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.62       |\n",
            "|    explained_variance   | 0.789       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.32        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0256     |\n",
            "|    std                  | 0.983       |\n",
            "|    value_loss           | 3.98        |\n",
            "-----------------------------------------\n",
            "Num timesteps: 11000\n",
            "Best mean reward: -22.78 - Last mean reward per episode: -21.70\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 12000\n",
            "Best mean reward: -21.70 - Last mean reward per episode: -20.21\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -20         |\n",
            "|    success_rate         | 0           |\n",
            "| time/                   |             |\n",
            "|    fps                  | 350         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 35          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022515707 |\n",
            "|    clip_fraction        | 0.298       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.58       |\n",
            "|    explained_variance   | 0.864       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.22        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0339     |\n",
            "|    std                  | 0.972       |\n",
            "|    value_loss           | 2.51        |\n",
            "-----------------------------------------\n",
            "Num timesteps: 13000\n",
            "Best mean reward: -20.21 - Last mean reward per episode: -19.65\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 14000\n",
            "Best mean reward: -19.65 - Last mean reward per episode: -19.23\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -19.2       |\n",
            "|    success_rate         | 0           |\n",
            "| time/                   |             |\n",
            "|    fps                  | 343         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015254879 |\n",
            "|    clip_fraction        | 0.18        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.55       |\n",
            "|    explained_variance   | 0.844       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.722       |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0197     |\n",
            "|    std                  | 0.969       |\n",
            "|    value_loss           | 1.5         |\n",
            "-----------------------------------------\n",
            "Num timesteps: 15000\n",
            "Best mean reward: -19.23 - Last mean reward per episode: -18.86\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 16000\n",
            "Best mean reward: -18.86 - Last mean reward per episode: -18.45\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 50         |\n",
            "|    ep_rew_mean          | -18.5      |\n",
            "|    success_rate         | 0          |\n",
            "| time/                   |            |\n",
            "|    fps                  | 340        |\n",
            "|    iterations           | 8          |\n",
            "|    time_elapsed         | 48         |\n",
            "|    total_timesteps      | 16384      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01205906 |\n",
            "|    clip_fraction        | 0.162      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -5.53      |\n",
            "|    explained_variance   | 0.86       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.507      |\n",
            "|    n_updates            | 70         |\n",
            "|    policy_gradient_loss | -0.016     |\n",
            "|    std                  | 0.965      |\n",
            "|    value_loss           | 1.19       |\n",
            "----------------------------------------\n",
            "Num timesteps: 17000\n",
            "Best mean reward: -18.45 - Last mean reward per episode: -18.56\n",
            "Num timesteps: 18000\n",
            "Best mean reward: -18.45 - Last mean reward per episode: -18.70\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -18.7       |\n",
            "|    success_rate         | 0           |\n",
            "| time/                   |             |\n",
            "|    fps                  | 344         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 53          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012201158 |\n",
            "|    clip_fraction        | 0.113       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.49       |\n",
            "|    explained_variance   | 0.798       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.504       |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0115     |\n",
            "|    std                  | 0.954       |\n",
            "|    value_loss           | 0.95        |\n",
            "-----------------------------------------\n",
            "Num timesteps: 19000\n",
            "Best mean reward: -18.45 - Last mean reward per episode: -18.21\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 20000\n",
            "Best mean reward: -18.21 - Last mean reward per episode: -17.69\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 50         |\n",
            "|    ep_rew_mean          | -17.8      |\n",
            "|    success_rate         | 0          |\n",
            "| time/                   |            |\n",
            "|    fps                  | 343        |\n",
            "|    iterations           | 10         |\n",
            "|    time_elapsed         | 59         |\n",
            "|    total_timesteps      | 20480      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00858104 |\n",
            "|    clip_fraction        | 0.0765     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -5.45      |\n",
            "|    explained_variance   | 0.776      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.417      |\n",
            "|    n_updates            | 90         |\n",
            "|    policy_gradient_loss | -0.00815   |\n",
            "|    std                  | 0.948      |\n",
            "|    value_loss           | 1.21       |\n",
            "----------------------------------------\n",
            "Num timesteps: 21000\n",
            "Best mean reward: -17.69 - Last mean reward per episode: -17.85\n",
            "Num timesteps: 22000\n",
            "Best mean reward: -17.69 - Last mean reward per episode: -17.55\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 50           |\n",
            "|    ep_rew_mean          | -17.2        |\n",
            "|    success_rate         | 0            |\n",
            "| time/                   |              |\n",
            "|    fps                  | 346          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 64           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0092028165 |\n",
            "|    clip_fraction        | 0.119        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -5.43        |\n",
            "|    explained_variance   | 0.807        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.365        |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.00954     |\n",
            "|    std                  | 0.943        |\n",
            "|    value_loss           | 0.959        |\n",
            "------------------------------------------\n",
            "Num timesteps: 23000\n",
            "Best mean reward: -17.55 - Last mean reward per episode: -16.99\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 24000\n",
            "Best mean reward: -16.99 - Last mean reward per episode: -16.67\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -16.4       |\n",
            "|    success_rate         | 0           |\n",
            "| time/                   |             |\n",
            "|    fps                  | 346         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 70          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012073751 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.42       |\n",
            "|    explained_variance   | 0.82        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.41        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0123     |\n",
            "|    std                  | 0.943       |\n",
            "|    value_loss           | 0.978       |\n",
            "-----------------------------------------\n",
            "Num timesteps: 25000\n",
            "Best mean reward: -16.67 - Last mean reward per episode: -16.28\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 26000\n",
            "Best mean reward: -16.28 - Last mean reward per episode: -15.55\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -15.2       |\n",
            "|    success_rate         | 0           |\n",
            "| time/                   |             |\n",
            "|    fps                  | 347         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 76          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011635627 |\n",
            "|    clip_fraction        | 0.157       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.41       |\n",
            "|    explained_variance   | 0.885       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.233       |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0128     |\n",
            "|    std                  | 0.941       |\n",
            "|    value_loss           | 0.732       |\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir2 = \"./logs_SAC/\"\n",
        "os.makedirs(log_dir2, exist_ok=True)"
      ],
      "metadata": {
        "id": "lqvQWE43Ox5_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback2 = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir2)\n",
        "\n",
        "env2 = gym.make('FetchReachDense-v3')\n",
        "env2 = Monitor(env2, log_dir2)\n",
        "vec_env2 = make_vec_env(lambda: env2, n_envs=1)\n",
        "\n",
        "model2 = SAC(\"MultiInputPolicy\",vec_env2, verbose=1)\n",
        "model2.learn(total_timesteps=25000,callback=callback2)\n",
        "model2.save(\"sac\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hamVlNf6Oagr",
        "outputId": "010bc9d2-b38d-4caa-efc7-5bb747f0317d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -27.5    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 77       |\n",
            "|    time_elapsed    | 2        |\n",
            "|    total_timesteps | 200      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.29    |\n",
            "|    critic_loss     | 0.0664   |\n",
            "|    ent_coef        | 0.971    |\n",
            "|    ent_coef_loss   | -0.198   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 99       |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -27.6    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 47       |\n",
            "|    time_elapsed    | 8        |\n",
            "|    total_timesteps | 400      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -6.56    |\n",
            "|    critic_loss     | 0.051    |\n",
            "|    ent_coef        | 0.914    |\n",
            "|    ent_coef_loss   | -0.602   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 299      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -26.9    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 45       |\n",
            "|    time_elapsed    | 13       |\n",
            "|    total_timesteps | 600      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.74    |\n",
            "|    critic_loss     | 0.0384   |\n",
            "|    ent_coef        | 0.861    |\n",
            "|    ent_coef_loss   | -1.01    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 499      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -26.4    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 43       |\n",
            "|    time_elapsed    | 18       |\n",
            "|    total_timesteps | 800      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -8.91    |\n",
            "|    critic_loss     | 0.0466   |\n",
            "|    ent_coef        | 0.811    |\n",
            "|    ent_coef_loss   | -1.41    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 699      |\n",
            "---------------------------------\n",
            "Num timesteps: 1000\n",
            "Best mean reward: -inf - Last mean reward per episode: -27.44\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -27.4    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 43       |\n",
            "|    time_elapsed    | 23       |\n",
            "|    total_timesteps | 1000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.98    |\n",
            "|    critic_loss     | 0.0367   |\n",
            "|    ent_coef        | 0.764    |\n",
            "|    ent_coef_loss   | -1.81    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 899      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -27.8    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 28       |\n",
            "|    total_timesteps | 1200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -11.1    |\n",
            "|    critic_loss     | 0.0415   |\n",
            "|    ent_coef        | 0.719    |\n",
            "|    ent_coef_loss   | -2.22    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1099     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -27.6    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 33       |\n",
            "|    total_timesteps | 1400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -12      |\n",
            "|    critic_loss     | 0.0255   |\n",
            "|    ent_coef        | 0.677    |\n",
            "|    ent_coef_loss   | -2.61    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1299     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -26.9    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 38       |\n",
            "|    total_timesteps | 1600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -13      |\n",
            "|    critic_loss     | 0.0229   |\n",
            "|    ent_coef        | 0.638    |\n",
            "|    ent_coef_loss   | -3       |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1499     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -26.8    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 43       |\n",
            "|    total_timesteps | 1800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -13.8    |\n",
            "|    critic_loss     | 0.0269   |\n",
            "|    ent_coef        | 0.601    |\n",
            "|    ent_coef_loss   | -3.41    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1699     |\n",
            "---------------------------------\n",
            "Num timesteps: 2000\n",
            "Best mean reward: -27.44 - Last mean reward per episode: -26.77\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -26.8    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 48       |\n",
            "|    total_timesteps | 2000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.5    |\n",
            "|    critic_loss     | 0.0243   |\n",
            "|    ent_coef        | 0.566    |\n",
            "|    ent_coef_loss   | -3.81    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -26.6    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 53       |\n",
            "|    total_timesteps | 2200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -15.2    |\n",
            "|    critic_loss     | 0.0239   |\n",
            "|    ent_coef        | 0.533    |\n",
            "|    ent_coef_loss   | -4.22    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2099     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -26.5    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 58       |\n",
            "|    total_timesteps | 2400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -15.7    |\n",
            "|    critic_loss     | 0.0126   |\n",
            "|    ent_coef        | 0.502    |\n",
            "|    ent_coef_loss   | -4.61    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2299     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -26      |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 63       |\n",
            "|    total_timesteps | 2600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16.3    |\n",
            "|    critic_loss     | 0.0141   |\n",
            "|    ent_coef        | 0.473    |\n",
            "|    ent_coef_loss   | -5       |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2499     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -25.7    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 56       |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 68       |\n",
            "|    total_timesteps | 2800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16.7    |\n",
            "|    critic_loss     | 0.0235   |\n",
            "|    ent_coef        | 0.446    |\n",
            "|    ent_coef_loss   | -5.4     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2699     |\n",
            "---------------------------------\n",
            "Num timesteps: 3000\n",
            "Best mean reward: -26.77 - Last mean reward per episode: -25.36\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -25.4    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 73       |\n",
            "|    total_timesteps | 3000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -17.1    |\n",
            "|    critic_loss     | 0.0105   |\n",
            "|    ent_coef        | 0.42     |\n",
            "|    ent_coef_loss   | -5.73    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -25      |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 64       |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 78       |\n",
            "|    total_timesteps | 3200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -17.4    |\n",
            "|    critic_loss     | 0.0229   |\n",
            "|    ent_coef        | 0.396    |\n",
            "|    ent_coef_loss   | -6.11    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3099     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -24.8    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 68       |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 83       |\n",
            "|    total_timesteps | 3400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -17.8    |\n",
            "|    critic_loss     | 0.0123   |\n",
            "|    ent_coef        | 0.373    |\n",
            "|    ent_coef_loss   | -6.45    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3299     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -24.7    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 72       |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 88       |\n",
            "|    total_timesteps | 3600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -18.2    |\n",
            "|    critic_loss     | 0.0142   |\n",
            "|    ent_coef        | 0.351    |\n",
            "|    ent_coef_loss   | -6.95    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3499     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -24.4    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 76       |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 92       |\n",
            "|    total_timesteps | 3800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -18.3    |\n",
            "|    critic_loss     | 0.0105   |\n",
            "|    ent_coef        | 0.331    |\n",
            "|    ent_coef_loss   | -7.26    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3699     |\n",
            "---------------------------------\n",
            "Num timesteps: 4000\n",
            "Best mean reward: -25.36 - Last mean reward per episode: -24.04\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -24      |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 98       |\n",
            "|    total_timesteps | 4000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -18.6    |\n",
            "|    critic_loss     | 0.0107   |\n",
            "|    ent_coef        | 0.312    |\n",
            "|    ent_coef_loss   | -7.6     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -23.9    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 84       |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 102      |\n",
            "|    total_timesteps | 4200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -18.6    |\n",
            "|    critic_loss     | 0.00862  |\n",
            "|    ent_coef        | 0.294    |\n",
            "|    ent_coef_loss   | -7.74    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4099     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -23.6    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 88       |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 107      |\n",
            "|    total_timesteps | 4400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19      |\n",
            "|    critic_loss     | 0.00838  |\n",
            "|    ent_coef        | 0.278    |\n",
            "|    ent_coef_loss   | -8.16    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4299     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -23.3    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 92       |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 112      |\n",
            "|    total_timesteps | 4600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19      |\n",
            "|    critic_loss     | 0.00925  |\n",
            "|    ent_coef        | 0.262    |\n",
            "|    ent_coef_loss   | -8.48    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4499     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -23      |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 96       |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 118      |\n",
            "|    total_timesteps | 4800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.4    |\n",
            "|    critic_loss     | 0.0102   |\n",
            "|    ent_coef        | 0.247    |\n",
            "|    ent_coef_loss   | -8.77    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4699     |\n",
            "---------------------------------\n",
            "Num timesteps: 5000\n",
            "Best mean reward: -24.04 - Last mean reward per episode: -22.74\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -22.7    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 123      |\n",
            "|    total_timesteps | 5000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.4    |\n",
            "|    critic_loss     | 0.0076   |\n",
            "|    ent_coef        | 0.233    |\n",
            "|    ent_coef_loss   | -8.87    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -22.2    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 104      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 127      |\n",
            "|    total_timesteps | 5200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.4    |\n",
            "|    critic_loss     | 0.00764  |\n",
            "|    ent_coef        | 0.22     |\n",
            "|    ent_coef_loss   | -9.37    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 5099     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -21.6    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 108      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 132      |\n",
            "|    total_timesteps | 5400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.6    |\n",
            "|    critic_loss     | 0.0142   |\n",
            "|    ent_coef        | 0.208    |\n",
            "|    ent_coef_loss   | -9.24    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 5299     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -21.3    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 112      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 137      |\n",
            "|    total_timesteps | 5600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.8    |\n",
            "|    critic_loss     | 0.00707  |\n",
            "|    ent_coef        | 0.196    |\n",
            "|    ent_coef_loss   | -9.66    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 5499     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -20.8    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 116      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 142      |\n",
            "|    total_timesteps | 5800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.6    |\n",
            "|    critic_loss     | 0.00873  |\n",
            "|    ent_coef        | 0.185    |\n",
            "|    ent_coef_loss   | -10      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 5699     |\n",
            "---------------------------------\n",
            "Num timesteps: 6000\n",
            "Best mean reward: -22.74 - Last mean reward per episode: -20.12\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -20.1    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 147      |\n",
            "|    total_timesteps | 6000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -20      |\n",
            "|    critic_loss     | 0.00931  |\n",
            "|    ent_coef        | 0.175    |\n",
            "|    ent_coef_loss   | -10.1    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 5899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -19.5    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 124      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 151      |\n",
            "|    total_timesteps | 6200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.7    |\n",
            "|    critic_loss     | 0.00849  |\n",
            "|    ent_coef        | 0.165    |\n",
            "|    ent_coef_loss   | -10.1    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6099     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -19      |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 128      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 156      |\n",
            "|    total_timesteps | 6400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -20.1    |\n",
            "|    critic_loss     | 0.00779  |\n",
            "|    ent_coef        | 0.156    |\n",
            "|    ent_coef_loss   | -10.6    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6299     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -18.6    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 132      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 161      |\n",
            "|    total_timesteps | 6600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.9    |\n",
            "|    critic_loss     | 0.00608  |\n",
            "|    ent_coef        | 0.148    |\n",
            "|    ent_coef_loss   | -10.7    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6499     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -18.1    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 136      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 166      |\n",
            "|    total_timesteps | 6800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.8    |\n",
            "|    critic_loss     | 0.00706  |\n",
            "|    ent_coef        | 0.14     |\n",
            "|    ent_coef_loss   | -11.1    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6699     |\n",
            "---------------------------------\n",
            "Num timesteps: 7000\n",
            "Best mean reward: -20.12 - Last mean reward per episode: -17.57\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -17.6    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 171      |\n",
            "|    total_timesteps | 7000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.8    |\n",
            "|    critic_loss     | 0.00704  |\n",
            "|    ent_coef        | 0.132    |\n",
            "|    ent_coef_loss   | -10.8    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -17.1    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 144      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 176      |\n",
            "|    total_timesteps | 7200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.7    |\n",
            "|    critic_loss     | 0.00632  |\n",
            "|    ent_coef        | 0.125    |\n",
            "|    ent_coef_loss   | -11.1    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7099     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -16.6    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 148      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 181      |\n",
            "|    total_timesteps | 7400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.7    |\n",
            "|    critic_loss     | 0.00652  |\n",
            "|    ent_coef        | 0.118    |\n",
            "|    ent_coef_loss   | -11.7    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7299     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -16.1    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 152      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 186      |\n",
            "|    total_timesteps | 7600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.7    |\n",
            "|    critic_loss     | 0.00683  |\n",
            "|    ent_coef        | 0.111    |\n",
            "|    ent_coef_loss   | -11.7    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7499     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -15.7    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 156      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 191      |\n",
            "|    total_timesteps | 7800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.2    |\n",
            "|    critic_loss     | 0.0051   |\n",
            "|    ent_coef        | 0.105    |\n",
            "|    ent_coef_loss   | -11.4    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7699     |\n",
            "---------------------------------\n",
            "Num timesteps: 8000\n",
            "Best mean reward: -17.57 - Last mean reward per episode: -15.35\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -15.3    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 195      |\n",
            "|    total_timesteps | 8000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.6    |\n",
            "|    critic_loss     | 0.00578  |\n",
            "|    ent_coef        | 0.0995   |\n",
            "|    ent_coef_loss   | -12      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -15      |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 164      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 200      |\n",
            "|    total_timesteps | 8200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.2    |\n",
            "|    critic_loss     | 0.0057   |\n",
            "|    ent_coef        | 0.094    |\n",
            "|    ent_coef_loss   | -11.8    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8099     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -14.6    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 168      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 205      |\n",
            "|    total_timesteps | 8400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.1    |\n",
            "|    critic_loss     | 0.00837  |\n",
            "|    ent_coef        | 0.0889   |\n",
            "|    ent_coef_loss   | -11.6    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8299     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -14.1    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 172      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 210      |\n",
            "|    total_timesteps | 8600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.2    |\n",
            "|    critic_loss     | 0.00607  |\n",
            "|    ent_coef        | 0.084    |\n",
            "|    ent_coef_loss   | -12.4    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8499     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -13.7    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 176      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 216      |\n",
            "|    total_timesteps | 8800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19      |\n",
            "|    critic_loss     | 0.0051   |\n",
            "|    ent_coef        | 0.0794   |\n",
            "|    ent_coef_loss   | -12.4    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8699     |\n",
            "---------------------------------\n",
            "Num timesteps: 9000\n",
            "Best mean reward: -15.35 - Last mean reward per episode: -13.47\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -13.5    |\n",
            "|    success_rate    | 0.01     |\n",
            "| time/              |          |\n",
            "|    episodes        | 180      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 221      |\n",
            "|    total_timesteps | 9000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -18.9    |\n",
            "|    critic_loss     | 0.00754  |\n",
            "|    ent_coef        | 0.0751   |\n",
            "|    ent_coef_loss   | -12.3    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -13.1    |\n",
            "|    success_rate    | 0.02     |\n",
            "| time/              |          |\n",
            "|    episodes        | 184      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 227      |\n",
            "|    total_timesteps | 9200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -18.8    |\n",
            "|    critic_loss     | 0.00633  |\n",
            "|    ent_coef        | 0.071    |\n",
            "|    ent_coef_loss   | -13.5    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9099     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -12.8    |\n",
            "|    success_rate    | 0.02     |\n",
            "| time/              |          |\n",
            "|    episodes        | 188      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 232      |\n",
            "|    total_timesteps | 9400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -18.6    |\n",
            "|    critic_loss     | 0.00537  |\n",
            "|    ent_coef        | 0.0671   |\n",
            "|    ent_coef_loss   | -13      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9299     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -12.6    |\n",
            "|    success_rate    | 0.02     |\n",
            "| time/              |          |\n",
            "|    episodes        | 192      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 237      |\n",
            "|    total_timesteps | 9600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -18.3    |\n",
            "|    critic_loss     | 0.00553  |\n",
            "|    ent_coef        | 0.0634   |\n",
            "|    ent_coef_loss   | -12.4    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9499     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -12.4    |\n",
            "|    success_rate    | 0.02     |\n",
            "| time/              |          |\n",
            "|    episodes        | 196      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 241      |\n",
            "|    total_timesteps | 9800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -18      |\n",
            "|    critic_loss     | 0.00571  |\n",
            "|    ent_coef        | 0.0599   |\n",
            "|    ent_coef_loss   | -12.6    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9699     |\n",
            "---------------------------------\n",
            "Num timesteps: 10000\n",
            "Best mean reward: -13.47 - Last mean reward per episode: -12.23\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -12.2    |\n",
            "|    success_rate    | 0.03     |\n",
            "| time/              |          |\n",
            "|    episodes        | 200      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 246      |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -17.9    |\n",
            "|    critic_loss     | 0.00488  |\n",
            "|    ent_coef        | 0.0567   |\n",
            "|    ent_coef_loss   | -12.4    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -12      |\n",
            "|    success_rate    | 0.03     |\n",
            "| time/              |          |\n",
            "|    episodes        | 204      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 251      |\n",
            "|    total_timesteps | 10200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -17.6    |\n",
            "|    critic_loss     | 0.00672  |\n",
            "|    ent_coef        | 0.0536   |\n",
            "|    ent_coef_loss   | -13.2    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 10099    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -11.9    |\n",
            "|    success_rate    | 0.03     |\n",
            "| time/              |          |\n",
            "|    episodes        | 208      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 256      |\n",
            "|    total_timesteps | 10400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -17.6    |\n",
            "|    critic_loss     | 0.00562  |\n",
            "|    ent_coef        | 0.0506   |\n",
            "|    ent_coef_loss   | -13.6    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 10299    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -11.7    |\n",
            "|    success_rate    | 0.03     |\n",
            "| time/              |          |\n",
            "|    episodes        | 212      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 262      |\n",
            "|    total_timesteps | 10600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -17.1    |\n",
            "|    critic_loss     | 0.00558  |\n",
            "|    ent_coef        | 0.0478   |\n",
            "|    ent_coef_loss   | -13.1    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 10499    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -11.6    |\n",
            "|    success_rate    | 0.03     |\n",
            "| time/              |          |\n",
            "|    episodes        | 216      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 267      |\n",
            "|    total_timesteps | 10800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -17      |\n",
            "|    critic_loss     | 0.00723  |\n",
            "|    ent_coef        | 0.0452   |\n",
            "|    ent_coef_loss   | -13.3    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 10699    |\n",
            "---------------------------------\n",
            "Num timesteps: 11000\n",
            "Best mean reward: -12.23 - Last mean reward per episode: -11.53\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -11.5    |\n",
            "|    success_rate    | 0.03     |\n",
            "| time/              |          |\n",
            "|    episodes        | 220      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 272      |\n",
            "|    total_timesteps | 11000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16.8    |\n",
            "|    critic_loss     | 0.00639  |\n",
            "|    ent_coef        | 0.0428   |\n",
            "|    ent_coef_loss   | -13.7    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 10899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -11.5    |\n",
            "|    success_rate    | 0.03     |\n",
            "| time/              |          |\n",
            "|    episodes        | 224      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 276      |\n",
            "|    total_timesteps | 11200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16.5    |\n",
            "|    critic_loss     | 0.00728  |\n",
            "|    ent_coef        | 0.0404   |\n",
            "|    ent_coef_loss   | -13.4    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11099    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -11.4    |\n",
            "|    success_rate    | 0.04     |\n",
            "| time/              |          |\n",
            "|    episodes        | 228      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 281      |\n",
            "|    total_timesteps | 11400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16.3    |\n",
            "|    critic_loss     | 0.00609  |\n",
            "|    ent_coef        | 0.0382   |\n",
            "|    ent_coef_loss   | -13.3    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11299    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -11.5    |\n",
            "|    success_rate    | 0.04     |\n",
            "| time/              |          |\n",
            "|    episodes        | 232      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 286      |\n",
            "|    total_timesteps | 11600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16.2    |\n",
            "|    critic_loss     | 0.00617  |\n",
            "|    ent_coef        | 0.0362   |\n",
            "|    ent_coef_loss   | -13.2    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11499    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -11.4    |\n",
            "|    success_rate    | 0.04     |\n",
            "| time/              |          |\n",
            "|    episodes        | 236      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 291      |\n",
            "|    total_timesteps | 11800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -15.8    |\n",
            "|    critic_loss     | 0.0076   |\n",
            "|    ent_coef        | 0.0342   |\n",
            "|    ent_coef_loss   | -14.8    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11699    |\n",
            "---------------------------------\n",
            "Num timesteps: 12000\n",
            "Best mean reward: -11.53 - Last mean reward per episode: -11.34\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -11.3    |\n",
            "|    success_rate    | 0.04     |\n",
            "| time/              |          |\n",
            "|    episodes        | 240      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 296      |\n",
            "|    total_timesteps | 12000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -15.4    |\n",
            "|    critic_loss     | 0.00748  |\n",
            "|    ent_coef        | 0.0324   |\n",
            "|    ent_coef_loss   | -13.1    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -11.4    |\n",
            "|    success_rate    | 0.04     |\n",
            "| time/              |          |\n",
            "|    episodes        | 244      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 301      |\n",
            "|    total_timesteps | 12200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.8    |\n",
            "|    critic_loss     | 0.00454  |\n",
            "|    ent_coef        | 0.0306   |\n",
            "|    ent_coef_loss   | -12.8    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 12099    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -11.4    |\n",
            "|    success_rate    | 0.04     |\n",
            "| time/              |          |\n",
            "|    episodes        | 248      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 306      |\n",
            "|    total_timesteps | 12400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.9    |\n",
            "|    critic_loss     | 0.00628  |\n",
            "|    ent_coef        | 0.029    |\n",
            "|    ent_coef_loss   | -12.5    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 12299    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -11.4    |\n",
            "|    success_rate    | 0.05     |\n",
            "| time/              |          |\n",
            "|    episodes        | 252      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 311      |\n",
            "|    total_timesteps | 12600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.6    |\n",
            "|    critic_loss     | 0.00581  |\n",
            "|    ent_coef        | 0.0274   |\n",
            "|    ent_coef_loss   | -13.2    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 12499    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -11.3    |\n",
            "|    success_rate    | 0.05     |\n",
            "| time/              |          |\n",
            "|    episodes        | 256      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 316      |\n",
            "|    total_timesteps | 12800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.3    |\n",
            "|    critic_loss     | 0.00512  |\n",
            "|    ent_coef        | 0.0259   |\n",
            "|    ent_coef_loss   | -13.6    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 12699    |\n",
            "---------------------------------\n",
            "Num timesteps: 13000\n",
            "Best mean reward: -11.34 - Last mean reward per episode: -11.16\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -11.2    |\n",
            "|    success_rate    | 0.05     |\n",
            "| time/              |          |\n",
            "|    episodes        | 260      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 320      |\n",
            "|    total_timesteps | 13000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.2    |\n",
            "|    critic_loss     | 0.00591  |\n",
            "|    ent_coef        | 0.0246   |\n",
            "|    ent_coef_loss   | -13.6    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 12899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -11      |\n",
            "|    success_rate    | 0.05     |\n",
            "| time/              |          |\n",
            "|    episodes        | 264      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 325      |\n",
            "|    total_timesteps | 13200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.1    |\n",
            "|    critic_loss     | 0.00423  |\n",
            "|    ent_coef        | 0.0233   |\n",
            "|    ent_coef_loss   | -13.7    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 13099    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -10.9    |\n",
            "|    success_rate    | 0.05     |\n",
            "| time/              |          |\n",
            "|    episodes        | 268      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 330      |\n",
            "|    total_timesteps | 13400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -13.6    |\n",
            "|    critic_loss     | 0.00513  |\n",
            "|    ent_coef        | 0.022    |\n",
            "|    ent_coef_loss   | -12.7    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 13299    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -11      |\n",
            "|    success_rate    | 0.05     |\n",
            "| time/              |          |\n",
            "|    episodes        | 272      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 334      |\n",
            "|    total_timesteps | 13600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -13.5    |\n",
            "|    critic_loss     | 0.00483  |\n",
            "|    ent_coef        | 0.0209   |\n",
            "|    ent_coef_loss   | -13.8    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 13499    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -10.9    |\n",
            "|    success_rate    | 0.05     |\n",
            "| time/              |          |\n",
            "|    episodes        | 276      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 339      |\n",
            "|    total_timesteps | 13800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -12.9    |\n",
            "|    critic_loss     | 0.00499  |\n",
            "|    ent_coef        | 0.0198   |\n",
            "|    ent_coef_loss   | -12.6    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 13699    |\n",
            "---------------------------------\n",
            "Num timesteps: 14000\n",
            "Best mean reward: -11.16 - Last mean reward per episode: -10.83\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -10.8    |\n",
            "|    success_rate    | 0.05     |\n",
            "| time/              |          |\n",
            "|    episodes        | 280      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 344      |\n",
            "|    total_timesteps | 14000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -13.1    |\n",
            "|    critic_loss     | 0.0043   |\n",
            "|    ent_coef        | 0.0187   |\n",
            "|    ent_coef_loss   | -12.1    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 13899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -10.9    |\n",
            "|    success_rate    | 0.04     |\n",
            "| time/              |          |\n",
            "|    episodes        | 284      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 349      |\n",
            "|    total_timesteps | 14200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -12.9    |\n",
            "|    critic_loss     | 0.00457  |\n",
            "|    ent_coef        | 0.0178   |\n",
            "|    ent_coef_loss   | -12.7    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 14099    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -10.8    |\n",
            "|    success_rate    | 0.04     |\n",
            "| time/              |          |\n",
            "|    episodes        | 288      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 353      |\n",
            "|    total_timesteps | 14400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -12.3    |\n",
            "|    critic_loss     | 0.00515  |\n",
            "|    ent_coef        | 0.0169   |\n",
            "|    ent_coef_loss   | -11.5    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 14299    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -10.8    |\n",
            "|    success_rate    | 0.04     |\n",
            "| time/              |          |\n",
            "|    episodes        | 292      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 358      |\n",
            "|    total_timesteps | 14600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -12      |\n",
            "|    critic_loss     | 0.00395  |\n",
            "|    ent_coef        | 0.016    |\n",
            "|    ent_coef_loss   | -11.6    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 14499    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -10.7    |\n",
            "|    success_rate    | 0.04     |\n",
            "| time/              |          |\n",
            "|    episodes        | 296      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 363      |\n",
            "|    total_timesteps | 14800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -12.1    |\n",
            "|    critic_loss     | 0.00506  |\n",
            "|    ent_coef        | 0.0152   |\n",
            "|    ent_coef_loss   | -12.4    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 14699    |\n",
            "---------------------------------\n",
            "Num timesteps: 15000\n",
            "Best mean reward: -10.83 - Last mean reward per episode: -10.60\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -10.6    |\n",
            "|    success_rate    | 0.04     |\n",
            "| time/              |          |\n",
            "|    episodes        | 300      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 367      |\n",
            "|    total_timesteps | 15000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -11.7    |\n",
            "|    critic_loss     | 0.0053   |\n",
            "|    ent_coef        | 0.0144   |\n",
            "|    ent_coef_loss   | -11.4    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 14899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -10.7    |\n",
            "|    success_rate    | 0.04     |\n",
            "| time/              |          |\n",
            "|    episodes        | 304      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 372      |\n",
            "|    total_timesteps | 15200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -11.5    |\n",
            "|    critic_loss     | 0.00436  |\n",
            "|    ent_coef        | 0.0137   |\n",
            "|    ent_coef_loss   | -11.6    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 15099    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -10.5    |\n",
            "|    success_rate    | 0.04     |\n",
            "| time/              |          |\n",
            "|    episodes        | 308      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 377      |\n",
            "|    total_timesteps | 15400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -11      |\n",
            "|    critic_loss     | 0.00492  |\n",
            "|    ent_coef        | 0.0131   |\n",
            "|    ent_coef_loss   | -11.1    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 15299    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -10.5    |\n",
            "|    success_rate    | 0.05     |\n",
            "| time/              |          |\n",
            "|    episodes        | 312      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 382      |\n",
            "|    total_timesteps | 15600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -11      |\n",
            "|    critic_loss     | 0.00436  |\n",
            "|    ent_coef        | 0.0124   |\n",
            "|    ent_coef_loss   | -10.5    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 15499    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -10.4    |\n",
            "|    success_rate    | 0.06     |\n",
            "| time/              |          |\n",
            "|    episodes        | 316      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 387      |\n",
            "|    total_timesteps | 15800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -10.6    |\n",
            "|    critic_loss     | 0.00528  |\n",
            "|    ent_coef        | 0.0118   |\n",
            "|    ent_coef_loss   | -11.3    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 15699    |\n",
            "---------------------------------\n",
            "Num timesteps: 16000\n",
            "Best mean reward: -10.60 - Last mean reward per episode: -10.27\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -10.3    |\n",
            "|    success_rate    | 0.06     |\n",
            "| time/              |          |\n",
            "|    episodes        | 320      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 392      |\n",
            "|    total_timesteps | 16000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -10.2    |\n",
            "|    critic_loss     | 0.00469  |\n",
            "|    ent_coef        | 0.0112   |\n",
            "|    ent_coef_loss   | -12.1    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 15899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -10.1    |\n",
            "|    success_rate    | 0.06     |\n",
            "| time/              |          |\n",
            "|    episodes        | 324      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 396      |\n",
            "|    total_timesteps | 16200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.92    |\n",
            "|    critic_loss     | 0.00548  |\n",
            "|    ent_coef        | 0.0107   |\n",
            "|    ent_coef_loss   | -9.69    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 16099    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -10.2    |\n",
            "|    success_rate    | 0.05     |\n",
            "| time/              |          |\n",
            "|    episodes        | 328      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 401      |\n",
            "|    total_timesteps | 16400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.86    |\n",
            "|    critic_loss     | 0.00534  |\n",
            "|    ent_coef        | 0.0102   |\n",
            "|    ent_coef_loss   | -10.4    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 16299    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -10      |\n",
            "|    success_rate    | 0.05     |\n",
            "| time/              |          |\n",
            "|    episodes        | 332      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 406      |\n",
            "|    total_timesteps | 16600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.65    |\n",
            "|    critic_loss     | 0.00413  |\n",
            "|    ent_coef        | 0.00974  |\n",
            "|    ent_coef_loss   | -9.38    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 16499    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.89    |\n",
            "|    success_rate    | 0.05     |\n",
            "| time/              |          |\n",
            "|    episodes        | 336      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 411      |\n",
            "|    total_timesteps | 16800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.45    |\n",
            "|    critic_loss     | 0.00357  |\n",
            "|    ent_coef        | 0.00928  |\n",
            "|    ent_coef_loss   | -8.38    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 16699    |\n",
            "---------------------------------\n",
            "Num timesteps: 17000\n",
            "Best mean reward: -10.27 - Last mean reward per episode: -9.78\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.78    |\n",
            "|    success_rate    | 0.05     |\n",
            "| time/              |          |\n",
            "|    episodes        | 340      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 416      |\n",
            "|    total_timesteps | 17000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.16    |\n",
            "|    critic_loss     | 0.00372  |\n",
            "|    ent_coef        | 0.00886  |\n",
            "|    ent_coef_loss   | -9.83    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 16899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.5     |\n",
            "|    success_rate    | 0.06     |\n",
            "| time/              |          |\n",
            "|    episodes        | 344      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 421      |\n",
            "|    total_timesteps | 17200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -8.97    |\n",
            "|    critic_loss     | 0.00539  |\n",
            "|    ent_coef        | 0.00846  |\n",
            "|    ent_coef_loss   | -7.69    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 17099    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.45    |\n",
            "|    success_rate    | 0.07     |\n",
            "| time/              |          |\n",
            "|    episodes        | 348      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 426      |\n",
            "|    total_timesteps | 17400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -8.92    |\n",
            "|    critic_loss     | 0.00669  |\n",
            "|    ent_coef        | 0.00808  |\n",
            "|    ent_coef_loss   | -8.47    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 17299    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.35    |\n",
            "|    success_rate    | 0.07     |\n",
            "| time/              |          |\n",
            "|    episodes        | 352      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 431      |\n",
            "|    total_timesteps | 17600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -8.35    |\n",
            "|    critic_loss     | 0.0049   |\n",
            "|    ent_coef        | 0.00773  |\n",
            "|    ent_coef_loss   | -7.03    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 17499    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.37    |\n",
            "|    success_rate    | 0.07     |\n",
            "| time/              |          |\n",
            "|    episodes        | 356      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 435      |\n",
            "|    total_timesteps | 17800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -8.07    |\n",
            "|    critic_loss     | 0.00516  |\n",
            "|    ent_coef        | 0.0074   |\n",
            "|    ent_coef_loss   | -6.62    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 17699    |\n",
            "---------------------------------\n",
            "Num timesteps: 18000\n",
            "Best mean reward: -9.78 - Last mean reward per episode: -9.45\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.45    |\n",
            "|    success_rate    | 0.08     |\n",
            "| time/              |          |\n",
            "|    episodes        | 360      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 440      |\n",
            "|    total_timesteps | 18000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -8.37    |\n",
            "|    critic_loss     | 0.00584  |\n",
            "|    ent_coef        | 0.00709  |\n",
            "|    ent_coef_loss   | -4.08    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 17899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.52    |\n",
            "|    success_rate    | 0.09     |\n",
            "| time/              |          |\n",
            "|    episodes        | 364      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 445      |\n",
            "|    total_timesteps | 18200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.93    |\n",
            "|    critic_loss     | 0.00425  |\n",
            "|    ent_coef        | 0.0068   |\n",
            "|    ent_coef_loss   | -5.09    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 18099    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.59    |\n",
            "|    success_rate    | 0.09     |\n",
            "| time/              |          |\n",
            "|    episodes        | 368      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 450      |\n",
            "|    total_timesteps | 18400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.74    |\n",
            "|    critic_loss     | 0.00504  |\n",
            "|    ent_coef        | 0.00653  |\n",
            "|    ent_coef_loss   | -5.81    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 18299    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.47    |\n",
            "|    success_rate    | 0.09     |\n",
            "| time/              |          |\n",
            "|    episodes        | 372      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 455      |\n",
            "|    total_timesteps | 18600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.03    |\n",
            "|    critic_loss     | 0.00451  |\n",
            "|    ent_coef        | 0.00627  |\n",
            "|    ent_coef_loss   | -6.18    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 18499    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.55    |\n",
            "|    success_rate    | 0.09     |\n",
            "| time/              |          |\n",
            "|    episodes        | 376      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 460      |\n",
            "|    total_timesteps | 18800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.46    |\n",
            "|    critic_loss     | 0.00356  |\n",
            "|    ent_coef        | 0.00603  |\n",
            "|    ent_coef_loss   | -5.57    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 18699    |\n",
            "---------------------------------\n",
            "Num timesteps: 19000\n",
            "Best mean reward: -9.45 - Last mean reward per episode: -9.52\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.52    |\n",
            "|    success_rate    | 0.09     |\n",
            "| time/              |          |\n",
            "|    episodes        | 380      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 465      |\n",
            "|    total_timesteps | 19000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.11    |\n",
            "|    critic_loss     | 0.00414  |\n",
            "|    ent_coef        | 0.00582  |\n",
            "|    ent_coef_loss   | -3.05    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 18899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.35    |\n",
            "|    success_rate    | 0.11     |\n",
            "| time/              |          |\n",
            "|    episodes        | 384      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 470      |\n",
            "|    total_timesteps | 19200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -6.94    |\n",
            "|    critic_loss     | 0.0061   |\n",
            "|    ent_coef        | 0.00561  |\n",
            "|    ent_coef_loss   | -4.48    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 19099    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.3     |\n",
            "|    success_rate    | 0.12     |\n",
            "| time/              |          |\n",
            "|    episodes        | 388      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 475      |\n",
            "|    total_timesteps | 19400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -6.98    |\n",
            "|    critic_loss     | 0.00628  |\n",
            "|    ent_coef        | 0.00543  |\n",
            "|    ent_coef_loss   | -4.34    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 19299    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.14    |\n",
            "|    success_rate    | 0.14     |\n",
            "| time/              |          |\n",
            "|    episodes        | 392      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 479      |\n",
            "|    total_timesteps | 19600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -6.22    |\n",
            "|    critic_loss     | 0.00401  |\n",
            "|    ent_coef        | 0.00525  |\n",
            "|    ent_coef_loss   | -3.02    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 19499    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.06    |\n",
            "|    success_rate    | 0.15     |\n",
            "| time/              |          |\n",
            "|    episodes        | 396      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 484      |\n",
            "|    total_timesteps | 19800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -6.1     |\n",
            "|    critic_loss     | 0.00626  |\n",
            "|    ent_coef        | 0.0051   |\n",
            "|    ent_coef_loss   | -2.64    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 19699    |\n",
            "---------------------------------\n",
            "Num timesteps: 20000\n",
            "Best mean reward: -9.45 - Last mean reward per episode: -9.05\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -9.05    |\n",
            "|    success_rate    | 0.16     |\n",
            "| time/              |          |\n",
            "|    episodes        | 400      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 488      |\n",
            "|    total_timesteps | 20000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -6.25    |\n",
            "|    critic_loss     | 0.00375  |\n",
            "|    ent_coef        | 0.00496  |\n",
            "|    ent_coef_loss   | -3.14    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 19899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.88    |\n",
            "|    success_rate    | 0.18     |\n",
            "| time/              |          |\n",
            "|    episodes        | 404      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 493      |\n",
            "|    total_timesteps | 20200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.95    |\n",
            "|    critic_loss     | 0.00642  |\n",
            "|    ent_coef        | 0.00484  |\n",
            "|    ent_coef_loss   | -3.77    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 20099    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.9     |\n",
            "|    success_rate    | 0.2      |\n",
            "| time/              |          |\n",
            "|    episodes        | 408      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 498      |\n",
            "|    total_timesteps | 20400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.44    |\n",
            "|    critic_loss     | 0.0056   |\n",
            "|    ent_coef        | 0.00472  |\n",
            "|    ent_coef_loss   | -2.68    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 20299    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.8     |\n",
            "|    success_rate    | 0.19     |\n",
            "| time/              |          |\n",
            "|    episodes        | 412      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 502      |\n",
            "|    total_timesteps | 20600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.09    |\n",
            "|    critic_loss     | 0.00477  |\n",
            "|    ent_coef        | 0.00462  |\n",
            "|    ent_coef_loss   | 1.64     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 20499    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.85    |\n",
            "|    success_rate    | 0.18     |\n",
            "| time/              |          |\n",
            "|    episodes        | 416      |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 507      |\n",
            "|    total_timesteps | 20800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.61    |\n",
            "|    critic_loss     | 0.00457  |\n",
            "|    ent_coef        | 0.00452  |\n",
            "|    ent_coef_loss   | -1.27    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 20699    |\n",
            "---------------------------------\n",
            "Num timesteps: 21000\n",
            "Best mean reward: -9.05 - Last mean reward per episode: -8.80\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.8     |\n",
            "|    success_rate    | 0.18     |\n",
            "| time/              |          |\n",
            "|    episodes        | 420      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 511      |\n",
            "|    total_timesteps | 21000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.15    |\n",
            "|    critic_loss     | 0.00468  |\n",
            "|    ent_coef        | 0.00441  |\n",
            "|    ent_coef_loss   | -1.63    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 20899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.74    |\n",
            "|    success_rate    | 0.2      |\n",
            "| time/              |          |\n",
            "|    episodes        | 424      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 516      |\n",
            "|    total_timesteps | 21200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -4.72    |\n",
            "|    critic_loss     | 0.00416  |\n",
            "|    ent_coef        | 0.0043   |\n",
            "|    ent_coef_loss   | -0.903   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 21099    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.54    |\n",
            "|    success_rate    | 0.2      |\n",
            "| time/              |          |\n",
            "|    episodes        | 428      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 521      |\n",
            "|    total_timesteps | 21400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -4.53    |\n",
            "|    critic_loss     | 0.00461  |\n",
            "|    ent_coef        | 0.00426  |\n",
            "|    ent_coef_loss   | 3.83     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 21299    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.42    |\n",
            "|    success_rate    | 0.21     |\n",
            "| time/              |          |\n",
            "|    episodes        | 432      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 525      |\n",
            "|    total_timesteps | 21600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -4.8     |\n",
            "|    critic_loss     | 0.00513  |\n",
            "|    ent_coef        | 0.00421  |\n",
            "|    ent_coef_loss   | 0.761    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 21499    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.47    |\n",
            "|    success_rate    | 0.22     |\n",
            "| time/              |          |\n",
            "|    episodes        | 436      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 530      |\n",
            "|    total_timesteps | 21800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -4.68    |\n",
            "|    critic_loss     | 0.00444  |\n",
            "|    ent_coef        | 0.00416  |\n",
            "|    ent_coef_loss   | -0.399   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 21699    |\n",
            "---------------------------------\n",
            "Num timesteps: 22000\n",
            "Best mean reward: -8.80 - Last mean reward per episode: -8.49\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.49    |\n",
            "|    success_rate    | 0.24     |\n",
            "| time/              |          |\n",
            "|    episodes        | 440      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 535      |\n",
            "|    total_timesteps | 22000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -4.1     |\n",
            "|    critic_loss     | 0.00496  |\n",
            "|    ent_coef        | 0.00404  |\n",
            "|    ent_coef_loss   | -0.638   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 21899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.46    |\n",
            "|    success_rate    | 0.25     |\n",
            "| time/              |          |\n",
            "|    episodes        | 444      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 539      |\n",
            "|    total_timesteps | 22200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -4.49    |\n",
            "|    critic_loss     | 0.00424  |\n",
            "|    ent_coef        | 0.00396  |\n",
            "|    ent_coef_loss   | -0.334   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 22099    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.3     |\n",
            "|    success_rate    | 0.27     |\n",
            "| time/              |          |\n",
            "|    episodes        | 448      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 544      |\n",
            "|    total_timesteps | 22400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.61    |\n",
            "|    critic_loss     | 0.00446  |\n",
            "|    ent_coef        | 0.00387  |\n",
            "|    ent_coef_loss   | -0.881   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 22299    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.16    |\n",
            "|    success_rate    | 0.29     |\n",
            "| time/              |          |\n",
            "|    episodes        | 452      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 548      |\n",
            "|    total_timesteps | 22600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.88    |\n",
            "|    critic_loss     | 0.00399  |\n",
            "|    ent_coef        | 0.00384  |\n",
            "|    ent_coef_loss   | 0.105    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 22499    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.12    |\n",
            "|    success_rate    | 0.31     |\n",
            "| time/              |          |\n",
            "|    episodes        | 456      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 553      |\n",
            "|    total_timesteps | 22800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.68    |\n",
            "|    critic_loss     | 0.00444  |\n",
            "|    ent_coef        | 0.0038   |\n",
            "|    ent_coef_loss   | -0.233   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 22699    |\n",
            "---------------------------------\n",
            "Num timesteps: 23000\n",
            "Best mean reward: -8.49 - Last mean reward per episode: -8.12\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.12    |\n",
            "|    success_rate    | 0.31     |\n",
            "| time/              |          |\n",
            "|    episodes        | 460      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 557      |\n",
            "|    total_timesteps | 23000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.58    |\n",
            "|    critic_loss     | 0.00547  |\n",
            "|    ent_coef        | 0.00381  |\n",
            "|    ent_coef_loss   | 0.656    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 22899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.01    |\n",
            "|    success_rate    | 0.3      |\n",
            "| time/              |          |\n",
            "|    episodes        | 464      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 564      |\n",
            "|    total_timesteps | 23200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.35    |\n",
            "|    critic_loss     | 0.00501  |\n",
            "|    ent_coef        | 0.00385  |\n",
            "|    ent_coef_loss   | -0.61    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 23099    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -7.94    |\n",
            "|    success_rate    | 0.32     |\n",
            "| time/              |          |\n",
            "|    episodes        | 468      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 569      |\n",
            "|    total_timesteps | 23400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.23    |\n",
            "|    critic_loss     | 0.0045   |\n",
            "|    ent_coef        | 0.00384  |\n",
            "|    ent_coef_loss   | 1.25     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 23299    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -7.97    |\n",
            "|    success_rate    | 0.33     |\n",
            "| time/              |          |\n",
            "|    episodes        | 472      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 573      |\n",
            "|    total_timesteps | 23600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.37    |\n",
            "|    critic_loss     | 0.00654  |\n",
            "|    ent_coef        | 0.00396  |\n",
            "|    ent_coef_loss   | -2.26    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 23499    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -7.83    |\n",
            "|    success_rate    | 0.36     |\n",
            "| time/              |          |\n",
            "|    episodes        | 476      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 578      |\n",
            "|    total_timesteps | 23800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -2.91    |\n",
            "|    critic_loss     | 0.00391  |\n",
            "|    ent_coef        | 0.00397  |\n",
            "|    ent_coef_loss   | -0.272   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 23699    |\n",
            "---------------------------------\n",
            "Num timesteps: 24000\n",
            "Best mean reward: -8.12 - Last mean reward per episode: -7.85\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -7.85    |\n",
            "|    success_rate    | 0.35     |\n",
            "| time/              |          |\n",
            "|    episodes        | 480      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 582      |\n",
            "|    total_timesteps | 24000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -2.68    |\n",
            "|    critic_loss     | 0.00346  |\n",
            "|    ent_coef        | 0.00406  |\n",
            "|    ent_coef_loss   | -0.915   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 23899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -7.87    |\n",
            "|    success_rate    | 0.33     |\n",
            "| time/              |          |\n",
            "|    episodes        | 484      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 587      |\n",
            "|    total_timesteps | 24200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -2.91    |\n",
            "|    critic_loss     | 0.00566  |\n",
            "|    ent_coef        | 0.00403  |\n",
            "|    ent_coef_loss   | -3.29    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 24099    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -7.93    |\n",
            "|    success_rate    | 0.33     |\n",
            "| time/              |          |\n",
            "|    episodes        | 488      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 592      |\n",
            "|    total_timesteps | 24400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -2.87    |\n",
            "|    critic_loss     | 0.00774  |\n",
            "|    ent_coef        | 0.004    |\n",
            "|    ent_coef_loss   | 0.625    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 24299    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.14    |\n",
            "|    success_rate    | 0.31     |\n",
            "| time/              |          |\n",
            "|    episodes        | 492      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 596      |\n",
            "|    total_timesteps | 24600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -2.13    |\n",
            "|    critic_loss     | 0.00511  |\n",
            "|    ent_coef        | 0.004    |\n",
            "|    ent_coef_loss   | -4.59    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 24499    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.17    |\n",
            "|    success_rate    | 0.32     |\n",
            "| time/              |          |\n",
            "|    episodes        | 496      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 601      |\n",
            "|    total_timesteps | 24800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -2.1     |\n",
            "|    critic_loss     | 0.005    |\n",
            "|    ent_coef        | 0.00388  |\n",
            "|    ent_coef_loss   | 0.972    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 24699    |\n",
            "---------------------------------\n",
            "Num timesteps: 25000\n",
            "Best mean reward: -7.85 - Last mean reward per episode: -8.25\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -8.25    |\n",
            "|    success_rate    | 0.3      |\n",
            "| time/              |          |\n",
            "|    episodes        | 500      |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 605      |\n",
            "|    total_timesteps | 25000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.97    |\n",
            "|    critic_loss     | 0.00465  |\n",
            "|    ent_coef        | 0.00379  |\n",
            "|    ent_coef_loss   | -0.946   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 24899    |\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def moving_average(values, window):\n",
        "    weights = np.repeat(1.0, window) / window\n",
        "    return np.convolve(values, weights, \"valid\")\n",
        "\n",
        "\n",
        "def plot_results(log_folder, title=\"Learning Curve\"):\n",
        "    x, y = ts2xy(load_results(log_folder), \"timesteps\")\n",
        "    y = moving_average(y, window=50)\n",
        "    x = x[len(x) - len(y) :]\n",
        "\n",
        "    fig = plt.figure(title)\n",
        "    plt.plot(x, y)\n",
        "    plt.xlabel(\"Number of Timesteps\")\n",
        "    plt.ylabel(\"Rewards\")\n",
        "    plt.title(title + \" Smoothed\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ilqdXICkPy_Y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results_both(log_folders, labels, title=\"Learning Curve\"):\n",
        "    fig = plt.figure(title)\n",
        "\n",
        "    for log_folder, label in zip(log_folders, labels):\n",
        "        x, y = ts2xy(load_results(log_folder), \"timesteps\")\n",
        "        y = moving_average(y, window=50)\n",
        "        x = x[len(x) - len(y) :]\n",
        "\n",
        "        plt.plot(x, y, label=label)\n",
        "\n",
        "    plt.xlabel(\"Number of Timesteps\")\n",
        "    plt.ylabel(\"Rewards\")\n",
        "    plt.title(title + \" Smoothed\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8kTGyaD7Qb-M"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_folders = ['/content/logs_PPO','/content/logs_SAC']\n",
        "labels = [\"PPO\", \"SAC\"]\n",
        "plot_results_both(log_folders, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "SqhVh82wQphk",
        "outputId": "8ac49545-3ae8-4dd6-e003-a629cb887d2a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}