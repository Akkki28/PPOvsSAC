{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMsKCCsP03CpxOuNKiMaS9K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akkki28/PPOvsSAC/blob/main/PPOvsSAC_AdroitHandDoor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3m1GHL4Nm81",
        "outputId": "80c608ef-9155-4785-93b0-803a013fcf2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium_robotics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOuJVjzVNsib",
        "outputId": "12ad996b-1679-4c1f-96bc-62c8b1fad09f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium_robotics\n",
            "  Downloading gymnasium_robotics-1.3.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting mujoco<3.2.0,>=2.2.0 (from gymnasium_robotics)\n",
            "  Downloading mujoco-3.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium_robotics) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium_robotics) (1.0.0)\n",
            "Collecting PettingZoo>=1.23.0 (from gymnasium_robotics)\n",
            "  Downloading pettingzoo-1.24.3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: Jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium_robotics) (3.1.5)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from gymnasium_robotics) (2.37.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->gymnasium_robotics) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->gymnasium_robotics) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->gymnasium_robotics) (0.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.0.3->gymnasium_robotics) (3.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mujoco<3.2.0,>=2.2.0->gymnasium_robotics) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.11/dist-packages (from mujoco<3.2.0,>=2.2.0->gymnasium_robotics) (1.12.0)\n",
            "Collecting glfw (from mujoco<3.2.0,>=2.2.0->gymnasium_robotics)\n",
            "  Downloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.11/dist-packages (from mujoco<3.2.0,>=2.2.0->gymnasium_robotics) (3.1.9)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio->gymnasium_robotics) (11.1.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium_robotics) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium_robotics) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium_robotics) (3.21.0)\n",
            "Downloading gymnasium_robotics-1.3.1-py3-none-any.whl (26.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mujoco-3.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pettingzoo-1.24.3-py3-none-any.whl (847 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.8/847.8 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: glfw, PettingZoo, mujoco, gymnasium_robotics\n",
            "Successfully installed PettingZoo-1.24.3 glfw-2.8.0 gymnasium_robotics-1.3.1 mujoco-3.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable_baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYSB8iJuNuJO",
        "outputId": "862515e1-d26c-4a7b-c55a-f32f4bd55070"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.0.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.5.1+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m906.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gymnasium as gym\n",
        "import gymnasium_robotics\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3 import PPO,SAC\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ],
      "metadata": {
        "id": "SBB3didhN7B9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"./logs_PPO/\"\n",
        "os.makedirs(log_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "1oQJuq0QNwCt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "import numpy as np\n",
        "\n",
        "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
        "    def __init__(self, check_freq: int, log_dir: str, verbose=1):\n",
        "        super().__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "        self.log_dir = log_dir\n",
        "        self.save_path = os.path.join(log_dir, \"best_model\")\n",
        "        self.best_mean_reward = -np.inf\n",
        "\n",
        "    def _init_callback(self) -> None:\n",
        "        if self.save_path is not None:\n",
        "            os.makedirs(self.save_path, exist_ok=True)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            x, y = ts2xy(load_results(self.log_dir), \"timesteps\")\n",
        "            if len(x) > 0:\n",
        "                mean_reward = np.mean(y[-100:])\n",
        "                if self.verbose > 0:\n",
        "                    print(f\"Num timesteps: {self.num_timesteps}\")\n",
        "                    print(\n",
        "                        f\"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}\"\n",
        "                    )\n",
        "\n",
        "                if mean_reward > self.best_mean_reward:\n",
        "                    self.best_mean_reward = mean_reward\n",
        "                    if self.verbose > 0:\n",
        "                        print(f\"Saving new best model to {self.save_path}.zip\")\n",
        "                    self.model.save(self.save_path)\n",
        "\n",
        "        return True"
      ],
      "metadata": {
        "id": "ZGHmggA0N18D"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir)\n",
        "\n",
        "gym.register_envs(gymnasium_robotics)\n",
        "env = gym.make('AdroitHandDoor-v1', max_episode_steps=400)\n",
        "env = Monitor(env, log_dir)\n",
        "vec_env = make_vec_env(lambda: env, n_envs=1)\n",
        "\n",
        "model1 = PPO(\"MlpPolicy\",vec_env, verbose=1)\n",
        "model1.learn(total_timesteps=25000,callback=callback)\n",
        "model1.save(\"ppo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAo70mWwOTWZ",
        "outputId": "5cd0a308-ca9d-41d4-89bb-8188c346b291"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num timesteps: 1000\n",
            "Best mean reward: -inf - Last mean reward per episode: -92.80\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 2000\n",
            "Best mean reward: -92.80 - Last mean reward per episode: -93.17\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | -93.2    |\n",
            "| time/              |          |\n",
            "|    fps             | 553      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Num timesteps: 3000\n",
            "Best mean reward: -92.80 - Last mean reward per episode: -92.71\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 4000\n",
            "Best mean reward: -92.71 - Last mean reward per episode: -92.63\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 400         |\n",
            "|    ep_rew_mean          | -92.6       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 474         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 8           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020126717 |\n",
            "|    clip_fraction        | 0.232       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -39.7       |\n",
            "|    explained_variance   | -0.0903     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.206       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0355     |\n",
            "|    std                  | 0.997       |\n",
            "|    value_loss           | 1.19        |\n",
            "-----------------------------------------\n",
            "Num timesteps: 5000\n",
            "Best mean reward: -92.63 - Last mean reward per episode: -92.66\n",
            "Num timesteps: 6000\n",
            "Best mean reward: -92.63 - Last mean reward per episode: -92.75\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 400         |\n",
            "|    ep_rew_mean          | -92.8       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 429         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 14          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018168095 |\n",
            "|    clip_fraction        | 0.177       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -39.6       |\n",
            "|    explained_variance   | -0.128      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0171      |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0338     |\n",
            "|    std                  | 0.994       |\n",
            "|    value_loss           | 0.756       |\n",
            "-----------------------------------------\n",
            "Num timesteps: 7000\n",
            "Best mean reward: -92.63 - Last mean reward per episode: -92.41\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 8000\n",
            "Best mean reward: -92.41 - Last mean reward per episode: -92.08\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 400         |\n",
            "|    ep_rew_mean          | -92.1       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 423         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021807533 |\n",
            "|    clip_fraction        | 0.195       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -39.5       |\n",
            "|    explained_variance   | -0.0889     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0812      |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0384     |\n",
            "|    std                  | 0.992       |\n",
            "|    value_loss           | 0.602       |\n",
            "-----------------------------------------\n",
            "Num timesteps: 9000\n",
            "Best mean reward: -92.08 - Last mean reward per episode: -92.14\n",
            "Num timesteps: 10000\n",
            "Best mean reward: -92.08 - Last mean reward per episode: -91.84\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 400        |\n",
            "|    ep_rew_mean          | -91.8      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 410        |\n",
            "|    iterations           | 5          |\n",
            "|    time_elapsed         | 24         |\n",
            "|    total_timesteps      | 10240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02092065 |\n",
            "|    clip_fraction        | 0.195      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -39.5      |\n",
            "|    explained_variance   | 0.00533    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0127    |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.0362    |\n",
            "|    std                  | 0.991      |\n",
            "|    value_loss           | 0.404      |\n",
            "----------------------------------------\n",
            "Num timesteps: 11000\n",
            "Best mean reward: -91.84 - Last mean reward per episode: -91.58\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 12000\n",
            "Best mean reward: -91.58 - Last mean reward per episode: -91.21\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 400         |\n",
            "|    ep_rew_mean          | -91.2       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 409         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 30          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024021195 |\n",
            "|    clip_fraction        | 0.241       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -39.5       |\n",
            "|    explained_variance   | -0.01       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0309     |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0381     |\n",
            "|    std                  | 0.991       |\n",
            "|    value_loss           | 0.303       |\n",
            "-----------------------------------------\n",
            "Num timesteps: 13000\n",
            "Best mean reward: -91.21 - Last mean reward per episode: -90.82\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 14000\n",
            "Best mean reward: -90.82 - Last mean reward per episode: -90.76\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 400        |\n",
            "|    ep_rew_mean          | -90.8      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 406        |\n",
            "|    iterations           | 7          |\n",
            "|    time_elapsed         | 35         |\n",
            "|    total_timesteps      | 14336      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02032363 |\n",
            "|    clip_fraction        | 0.2        |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -39.5      |\n",
            "|    explained_variance   | -0.0147    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.00787   |\n",
            "|    n_updates            | 60         |\n",
            "|    policy_gradient_loss | -0.0366    |\n",
            "|    std                  | 0.989      |\n",
            "|    value_loss           | 0.166      |\n",
            "----------------------------------------\n",
            "Num timesteps: 15000\n",
            "Best mean reward: -90.76 - Last mean reward per episode: -90.48\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 16000\n",
            "Best mean reward: -90.48 - Last mean reward per episode: -89.97\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 400        |\n",
            "|    ep_rew_mean          | -90        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 404        |\n",
            "|    iterations           | 8          |\n",
            "|    time_elapsed         | 40         |\n",
            "|    total_timesteps      | 16384      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02288123 |\n",
            "|    clip_fraction        | 0.215      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -39.4      |\n",
            "|    explained_variance   | -0.0627    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0277    |\n",
            "|    n_updates            | 70         |\n",
            "|    policy_gradient_loss | -0.041     |\n",
            "|    std                  | 0.989      |\n",
            "|    value_loss           | 0.132      |\n",
            "----------------------------------------\n",
            "Num timesteps: 17000\n",
            "Best mean reward: -89.97 - Last mean reward per episode: -89.72\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 18000\n",
            "Best mean reward: -89.72 - Last mean reward per episode: -89.51\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 400         |\n",
            "|    ep_rew_mean          | -89.4       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 405         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 45          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023050968 |\n",
            "|    clip_fraction        | 0.231       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -39.4       |\n",
            "|    explained_variance   | -0.0533     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.06       |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0448     |\n",
            "|    std                  | 0.989       |\n",
            "|    value_loss           | 0.0704      |\n",
            "-----------------------------------------\n",
            "Num timesteps: 19000\n",
            "Best mean reward: -89.51 - Last mean reward per episode: -89.29\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 20000\n",
            "Best mean reward: -89.29 - Last mean reward per episode: -88.91\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 400       |\n",
            "|    ep_rew_mean          | -88.8     |\n",
            "| time/                   |           |\n",
            "|    fps                  | 397       |\n",
            "|    iterations           | 10        |\n",
            "|    time_elapsed         | 51        |\n",
            "|    total_timesteps      | 20480     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0259488 |\n",
            "|    clip_fraction        | 0.267     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -39.4     |\n",
            "|    explained_variance   | -0.0158   |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -0.0562   |\n",
            "|    n_updates            | 90        |\n",
            "|    policy_gradient_loss | -0.0491   |\n",
            "|    std                  | 0.985     |\n",
            "|    value_loss           | 0.0788    |\n",
            "---------------------------------------\n",
            "Num timesteps: 21000\n",
            "Best mean reward: -88.91 - Last mean reward per episode: -88.63\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 22000\n",
            "Best mean reward: -88.63 - Last mean reward per episode: -88.18\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 400         |\n",
            "|    ep_rew_mean          | -88.1       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 394         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 57          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026778758 |\n",
            "|    clip_fraction        | 0.291       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -39.3       |\n",
            "|    explained_variance   | 0.293       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0436     |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0522     |\n",
            "|    std                  | 0.985       |\n",
            "|    value_loss           | 0.0502      |\n",
            "-----------------------------------------\n",
            "Num timesteps: 23000\n",
            "Best mean reward: -88.18 - Last mean reward per episode: -87.88\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 24000\n",
            "Best mean reward: -87.88 - Last mean reward per episode: -87.50\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 400       |\n",
            "|    ep_rew_mean          | -87.4     |\n",
            "| time/                   |           |\n",
            "|    fps                  | 391       |\n",
            "|    iterations           | 12        |\n",
            "|    time_elapsed         | 62        |\n",
            "|    total_timesteps      | 24576     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0250739 |\n",
            "|    clip_fraction        | 0.293     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -39.3     |\n",
            "|    explained_variance   | 0.491     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -0.0236   |\n",
            "|    n_updates            | 110       |\n",
            "|    policy_gradient_loss | -0.0522   |\n",
            "|    std                  | 0.983     |\n",
            "|    value_loss           | 0.0546    |\n",
            "---------------------------------------\n",
            "Num timesteps: 25000\n",
            "Best mean reward: -87.50 - Last mean reward per episode: -87.21\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "Num timesteps: 26000\n",
            "Best mean reward: -87.21 - Last mean reward per episode: -86.74\n",
            "Saving new best model to ./logs_PPO/best_model.zip\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 400         |\n",
            "|    ep_rew_mean          | -86.6       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 392         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 67          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027253123 |\n",
            "|    clip_fraction        | 0.304       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -39.3       |\n",
            "|    explained_variance   | 0.492       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.062      |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0499     |\n",
            "|    std                  | 0.983       |\n",
            "|    value_loss           | 0.0492      |\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir2 = \"./logs_SAC/\"\n",
        "os.makedirs(log_dir2, exist_ok=True)"
      ],
      "metadata": {
        "id": "lqvQWE43Ox5_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback2 = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir2)\n",
        "\n",
        "env2 = gym.make('AdroitHandDoor-v1', max_episode_steps=400)\n",
        "env2 = Monitor(env2, log_dir2)\n",
        "vec_env2 = make_vec_env(lambda: env2, n_envs=1)\n",
        "\n",
        "model2 = SAC(\"MlpPolicy\",vec_env2, verbose=1)\n",
        "model2.learn(total_timesteps=25000,callback=callback2)\n",
        "model2.save(\"sac\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hamVlNf6Oagr",
        "outputId": "5c2900da-2955-48cc-f744-e3ab8c2e3fe1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Num timesteps: 1000\n",
            "Best mean reward: -inf - Last mean reward per episode: -90.94\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | -90.6    |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 85       |\n",
            "|    time_elapsed    | 18       |\n",
            "|    total_timesteps | 1600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -104     |\n",
            "|    critic_loss     | 1.04     |\n",
            "|    ent_coef        | 0.638    |\n",
            "|    ent_coef_loss   | -20.8    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1499     |\n",
            "---------------------------------\n",
            "Num timesteps: 2000\n",
            "Best mean reward: -90.94 - Last mean reward per episode: -90.32\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "Num timesteps: 3000\n",
            "Best mean reward: -90.32 - Last mean reward per episode: -90.27\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | -90.3    |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 82       |\n",
            "|    time_elapsed    | 38       |\n",
            "|    total_timesteps | 3200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -159     |\n",
            "|    critic_loss     | 1.03     |\n",
            "|    ent_coef        | 0.396    |\n",
            "|    ent_coef_loss   | -42.5    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3099     |\n",
            "---------------------------------\n",
            "Num timesteps: 4000\n",
            "Best mean reward: -90.27 - Last mean reward per episode: -90.08\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | -89.7    |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 82       |\n",
            "|    time_elapsed    | 58       |\n",
            "|    total_timesteps | 4800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -184     |\n",
            "|    critic_loss     | 0.937    |\n",
            "|    ent_coef        | 0.247    |\n",
            "|    ent_coef_loss   | -61.1    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4699     |\n",
            "---------------------------------\n",
            "Num timesteps: 5000\n",
            "Best mean reward: -90.08 - Last mean reward per episode: -89.71\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "Num timesteps: 6000\n",
            "Best mean reward: -89.71 - Last mean reward per episode: -88.07\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | -87.8    |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 78       |\n",
            "|    total_timesteps | 6400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -193     |\n",
            "|    critic_loss     | 0.643    |\n",
            "|    ent_coef        | 0.154    |\n",
            "|    ent_coef_loss   | -81.2    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6299     |\n",
            "---------------------------------\n",
            "Num timesteps: 7000\n",
            "Best mean reward: -88.07 - Last mean reward per episode: -87.60\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "Num timesteps: 8000\n",
            "Best mean reward: -87.60 - Last mean reward per episode: -86.09\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | -86.1    |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 98       |\n",
            "|    total_timesteps | 8000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -192     |\n",
            "|    critic_loss     | 0.489    |\n",
            "|    ent_coef        | 0.0971   |\n",
            "|    ent_coef_loss   | -93.4    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7899     |\n",
            "---------------------------------\n",
            "Num timesteps: 9000\n",
            "Best mean reward: -86.09 - Last mean reward per episode: -85.44\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | -84.9    |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 117      |\n",
            "|    total_timesteps | 9600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -188     |\n",
            "|    critic_loss     | 0.434    |\n",
            "|    ent_coef        | 0.0663   |\n",
            "|    ent_coef_loss   | -51.8    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9499     |\n",
            "---------------------------------\n",
            "Num timesteps: 10000\n",
            "Best mean reward: -85.44 - Last mean reward per episode: -84.78\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "Num timesteps: 11000\n",
            "Best mean reward: -84.78 - Last mean reward per episode: -83.80\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | -83.9    |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 137      |\n",
            "|    total_timesteps | 11200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -184     |\n",
            "|    critic_loss     | 0.327    |\n",
            "|    ent_coef        | 0.0525   |\n",
            "|    ent_coef_loss   | -12      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11099    |\n",
            "---------------------------------\n",
            "Num timesteps: 12000\n",
            "Best mean reward: -83.80 - Last mean reward per episode: -83.71\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | -83.4    |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 157      |\n",
            "|    total_timesteps | 12800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -176     |\n",
            "|    critic_loss     | 0.366    |\n",
            "|    ent_coef        | 0.0421   |\n",
            "|    ent_coef_loss   | -8.29    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 12699    |\n",
            "---------------------------------\n",
            "Num timesteps: 13000\n",
            "Best mean reward: -83.71 - Last mean reward per episode: -83.38\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "Num timesteps: 14000\n",
            "Best mean reward: -83.38 - Last mean reward per episode: -82.68\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | -82.1    |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 177      |\n",
            "|    total_timesteps | 14400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -169     |\n",
            "|    critic_loss     | 0.327    |\n",
            "|    ent_coef        | 0.0324   |\n",
            "|    ent_coef_loss   | 8.02     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 14299    |\n",
            "---------------------------------\n",
            "Num timesteps: 15000\n",
            "Best mean reward: -82.68 - Last mean reward per episode: -81.85\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "Num timesteps: 16000\n",
            "Best mean reward: -81.85 - Last mean reward per episode: -81.74\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | -81.7    |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 197      |\n",
            "|    total_timesteps | 16000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -162     |\n",
            "|    critic_loss     | 0.376    |\n",
            "|    ent_coef        | 0.0268   |\n",
            "|    ent_coef_loss   | -2.53    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 15899    |\n",
            "---------------------------------\n",
            "Num timesteps: 17000\n",
            "Best mean reward: -81.74 - Last mean reward per episode: -81.66\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | -81.7    |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 216      |\n",
            "|    total_timesteps | 17600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -155     |\n",
            "|    critic_loss     | 0.265    |\n",
            "|    ent_coef        | 0.0239   |\n",
            "|    ent_coef_loss   | -31.2    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 17499    |\n",
            "---------------------------------\n",
            "Num timesteps: 18000\n",
            "Best mean reward: -81.66 - Last mean reward per episode: -81.70\n",
            "Num timesteps: 19000\n",
            "Best mean reward: -81.66 - Last mean reward per episode: -81.02\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | -80.7    |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 236      |\n",
            "|    total_timesteps | 19200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -147     |\n",
            "|    critic_loss     | 0.174    |\n",
            "|    ent_coef        | 0.026    |\n",
            "|    ent_coef_loss   | 8.23     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 19099    |\n",
            "---------------------------------\n",
            "Num timesteps: 20000\n",
            "Best mean reward: -81.02 - Last mean reward per episode: -80.53\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | -80.5    |\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 256      |\n",
            "|    total_timesteps | 20800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -140     |\n",
            "|    critic_loss     | 0.159    |\n",
            "|    ent_coef        | 0.0212   |\n",
            "|    ent_coef_loss   | -49      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 20699    |\n",
            "---------------------------------\n",
            "Num timesteps: 21000\n",
            "Best mean reward: -80.53 - Last mean reward per episode: -80.55\n",
            "Num timesteps: 22000\n",
            "Best mean reward: -80.53 - Last mean reward per episode: -80.58\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | -80.6    |\n",
            "| time/              |          |\n",
            "|    episodes        | 56       |\n",
            "|    fps             | 80       |\n",
            "|    time_elapsed    | 276      |\n",
            "|    total_timesteps | 22400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -133     |\n",
            "|    critic_loss     | 0.149    |\n",
            "|    ent_coef        | 0.0164   |\n",
            "|    ent_coef_loss   | -10.1    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 22299    |\n",
            "---------------------------------\n",
            "Num timesteps: 23000\n",
            "Best mean reward: -80.53 - Last mean reward per episode: -80.55\n",
            "Num timesteps: 24000\n",
            "Best mean reward: -80.53 - Last mean reward per episode: -80.41\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 400      |\n",
            "|    ep_rew_mean     | -80.4    |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 80       |\n",
            "|    time_elapsed    | 296      |\n",
            "|    total_timesteps | 24000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -124     |\n",
            "|    critic_loss     | 0.123    |\n",
            "|    ent_coef        | 0.0153   |\n",
            "|    ent_coef_loss   | -0.63    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 23899    |\n",
            "---------------------------------\n",
            "Num timesteps: 25000\n",
            "Best mean reward: -80.41 - Last mean reward per episode: -80.13\n",
            "Saving new best model to ./logs_SAC/best_model.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def moving_average(values, window):\n",
        "    weights = np.repeat(1.0, window) / window\n",
        "    return np.convolve(values, weights, \"valid\")\n",
        "\n",
        "\n",
        "def plot_results(log_folder, title=\"Learning Curve\"):\n",
        "    x, y = ts2xy(load_results(log_folder), \"timesteps\")\n",
        "    y = moving_average(y, window=50)\n",
        "    x = x[len(x) - len(y) :]\n",
        "\n",
        "    fig = plt.figure(title)\n",
        "    plt.plot(x, y)\n",
        "    plt.xlabel(\"Number of Timesteps\")\n",
        "    plt.ylabel(\"Rewards\")\n",
        "    plt.title(title + \" Smoothed\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ilqdXICkPy_Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results_both(log_folders, labels, title=\"Learning Curve\"):\n",
        "    fig = plt.figure(title)\n",
        "\n",
        "    for log_folder, label in zip(log_folders, labels):\n",
        "        x, y = ts2xy(load_results(log_folder), \"timesteps\")\n",
        "        y = moving_average(y, window=50)\n",
        "        x = x[len(x) - len(y) :]\n",
        "\n",
        "        plt.plot(x, y, label=label)\n",
        "\n",
        "    plt.xlabel(\"Number of Timesteps\")\n",
        "    plt.ylabel(\"Rewards\")\n",
        "    plt.title(title + \" Smoothed\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8kTGyaD7Qb-M"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_folders = ['/content/logs_PPO','/content/logs_SAC']\n",
        "labels = [\"PPO\", \"SAC\"]\n",
        "plot_results_both(log_folders, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "SqhVh82wQphk",
        "outputId": "6c9bf748-238b-4710-9507-e1f61cc8b7a1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}